# cdc-sample

## Abstract

This reference architecture presents a scalable solution for real-time data synchronization from an Oracle database to
Apache Kafka using Kafka Connect JDBC or Debezium. The solution captures changes from the database using triggers that
populate a CHANGE_TRACKING table, which Kafka Connect polls to stream events to Kafka topics. This architecture enables
seamless integration with downstream systems and supports event-driven microservices. The document includes
architectural
diagrams, SQL scripts, trigger logic, a step-by-step validation guide, and Kafka Connect configuration for end-to-end
implementation.

## Architecture Diagram

         ┌──────────────────────────┐
         │      Oracle Database     │
         │ ┌──────────────────────┐ │
         │ │  Application Tables  │ │
         │ └──────────────────────┘ │
         │            ▲             │
         │            │ (Trigger)   │
         │            ▼             │
         │ ┌──────────────────────┐ │
         │ │   CHANGE_TRACKING    │ │
         │ └──────────────────────┘ │
         └───────────┬──────────────┘
                     │ (CDC Polling)
                     ▼
        ┌──────────────────────────┐
        │     Kafka Connect        │
        │  (JDBC or Debezium CDC)  │
        └───────────┬──────────────┘
                     │ (JSON Events)
                     ▼
        ┌──────────────────────────┐
        │        Kafka Broker      │
        │ (Topic: oracle_events)   │
        └───────────┬──────────────┘
                     │
        ┌───────────▼────────────┐
        │     Kafka Consumers    │
        │ (External Systems/APIs)│
        └────────────────────────┘

## How to set up oracledb using docker

1. In a web browser, sign in to the Oracle Container Registry using an Oracle account
   at https://container-registry.oracle.com.

2. Select the profile name. Select the profile name, and in the profile menu that appears select **Auth Token**.

3. Generate the **Secret Key**. Select Generate Secret Key and note down the secret key. This is only displayed once,
   during the initial generation.

4. (Optional) Regenerate the Secret Key. If you lose or forget the secret key, generate a new one by selecting Delete
   Secret Key, then select Generate Secret Key again.

5. Navigate to `database -> express` and accept the license agreement.

### Docker login

```bash
   docker login container-registry.oracle.com -u your-email@example.com
   # Enter the auth token when prompted for password
```

### Pull the image

```bash
  docker pull --platform=linux/amd64  container-registry.oracle.com/database/express:latest
```

### Run docker-compose

```bash
  docker-compose up -d
```

### Connection details

| Item        | Value                 |
|-------------|-----------------------|
| Host        | `localhost`           |
| Port        | `1521`                |
| SID/Service | `XEPDB1` or `XE`      |
| Username    | `SYSTEM`              |
| Password    | `MySecurePassword123` |

| Field            | Value                                                    |
|------------------|----------------------------------------------------------|
| **Host**         | `localhost`                                              |
| **Port**         | `1521`                                                   |
| **Service Name** | `XEPDB1` (for 21c XE)                                    |
| **SID**          | `XE` (if you’re using SID-style connection)              |
| **Username**     | `SYSTEM`                                                 |
| **Password**     | `MySecurePassword123` (as per your `docker-compose.yml`) |

### Connect using SQL Developer (GUI)

1. Download and open [Oracle SQL Developer](https://www.oracle.com/tools/downloads/sqldev-downloads.html).
2. Create a new connection:

    * **Username**: `SYSTEM`
    * **Password**: `MySecurePassword123`
    * **Hostname**: `localhost`
    * **Port**: `1521`
    * **Service name**: `XEPDB1` (not SID)
3. Click **Test**, then **Connect**.

---

## Database set up

### Oracledb

``` sql
-- Create ORDERS table
CREATE TABLE ORDERS (
  ID              NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  CUSTOMER_ID     NUMBER NOT NULL,
  ORDER_DATE      DATE DEFAULT SYSDATE NOT NULL,
  STATUS          VARCHAR2(20 CHAR) DEFAULT 'PENDING' NOT NULL,
  TOTAL_AMOUNT    NUMBER(10, 2) NOT NULL,
  CURRENCY        VARCHAR2(3 CHAR) DEFAULT 'USD' NOT NULL,
  NOTES           VARCHAR2(500 CHAR),
  CREATED_AT    TIMESTAMP(9) DEFAULT SYSTIMESTAMP NOT NULL
);

-- Create CHANGE_TRACKING table
CREATE TABLE CHANGE_TRACKING (
   ID                  NUMBER(19,0) GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
   TABLE_NAME          VARCHAR2(100 CHAR) NOT NULL,
   TYPE                VARCHAR2(20 CHAR) NOT NULL,
   DATA_CONTENT_TYPE   VARCHAR2(100 CHAR),
   DATA                CLOB CONSTRAINT CHK_JSON_DATA CHECK (DATA IS JSON),
   DATA_BASE64         CLOB,
   CREATED_AT    TIMESTAMP(9) DEFAULT SYSTIMESTAMP NOT NULL
);

-- Trigger function for ORDERS change tracking
CREATE OR REPLACE TRIGGER TRG_ORDERS_CHANGE_TRACKING
AFTER INSERT OR UPDATE OR DELETE ON ORDERS
FOR EACH ROW
DECLARE
  v_action_type   VARCHAR2(10);
  v_json_data     CLOB;
  v_data_base64   CLOB;
BEGIN
  IF INSERTING THEN
    v_action_type := 'INSERT';
    v_json_data := TO_CLOB(JSON_OBJECT(
      'id' VALUE :NEW.ID,
      'customer_id' VALUE :NEW.CUSTOMER_ID,
      'order_date' VALUE TO_CHAR(:NEW.ORDER_DATE, 'YYYY-MM-DD"T"HH24:MI:SS'),
      'status' VALUE :NEW.STATUS,
      'total_amount' VALUE TO_CHAR(:NEW.TOTAL_AMOUNT),
      'currency' VALUE :NEW.CURRENCY,
      'notes' VALUE :NEW.NOTES,
      'created_at' VALUE TO_CHAR(:NEW.CREATED_AT, 'YYYY-MM-DD"T"HH24:MI:SS')
    ));

  ELSIF UPDATING THEN
    v_action_type := 'UPDATE';
    v_json_data := TO_CLOB(JSON_OBJECT(
      'id' VALUE :NEW.ID,
      'customer_id' VALUE :NEW.CUSTOMER_ID,
      'order_date' VALUE TO_CHAR(:NEW.ORDER_DATE, 'YYYY-MM-DD"T"HH24:MI:SS'),
      'status' VALUE :NEW.STATUS,
      'total_amount' VALUE TO_CHAR(:NEW.TOTAL_AMOUNT),
      'currency' VALUE :NEW.CURRENCY,
      'notes' VALUE :NEW.NOTES,
      'created_at' VALUE TO_CHAR(:NEW.CREATED_AT, 'YYYY-MM-DD"T"HH24:MI:SS')
    ));

  ELSIF DELETING THEN
    v_action_type := 'DELETE';
    v_json_data := TO_CLOB(JSON_OBJECT(
      'id' VALUE :OLD.ID,
      'customer_id' VALUE :OLD.CUSTOMER_ID,
      'order_date' VALUE TO_CHAR(:OLD.ORDER_DATE, 'YYYY-MM-DD"T"HH24:MI:SS'),
      'STATUS' VALUE :OLD.STATUS,
      'status' VALUE TO_CHAR(:OLD.TOTAL_AMOUNT),
      'currency' VALUE :OLD.CURRENCY,
      'notes' VALUE :OLD.NOTES,
      'created_at' VALUE TO_CHAR(:NEW.CREATED_AT, 'YYYY-MM-DD"T"HH24:MI:SS')

    ));
  END IF;

  SELECT UTL_RAW.CAST_TO_VARCHAR2(
           UTL_ENCODE.BASE64_ENCODE(UTL_RAW.CAST_TO_RAW(v_json_data))
         )
  INTO v_data_base64
  FROM DUAL;

  INSERT INTO CHANGE_TRACKING (
    TABLE_NAME,
    TYPE,
    DATA_CONTENT_TYPE,
    DATA,
    DATA_BASE64
  ) VALUES (
    'ORDERS',
    v_action_type,
    'application/json',
    v_json_data,
    v_data_base64
  );
END;
/
```

### Postgresql

```sql
-- Create ORDERS table
CREATE TABLE orders (
    id              BIGSERIAL PRIMARY KEY,
    customer_id     BIGINT NOT NULL,
    order_date      DATE DEFAULT CURRENT_DATE NOT NULL,
    status          VARCHAR(20) DEFAULT 'PENDING' NOT NULL,
    total_amount    NUMERIC(10, 2) NOT NULL,
    currency        VARCHAR(3) DEFAULT 'USD' NOT NULL,
    notes           VARCHAR(500),
    created_at      TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP NOT NULL
);

-- Create CHANGE_TRACKING table
CREATE TABLE change_tracking (
    id                  BIGSERIAL PRIMARY KEY,
    table_name          VARCHAR(100) NOT NULL,
    type                VARCHAR(20) NOT NULL,
    data_content_type   VARCHAR(100),
    data                JSONB CHECK (jsonb_typeof(data) = 'object'),
    data_base64         TEXT,
    created_at          TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP NOT NULL
);

-- Trigger function for ORDERS change tracking
CREATE OR REPLACE FUNCTION trg_orders_change_tracking_fn()
RETURNS TRIGGER AS $$
DECLARE
    v_action_type TEXT;
    v_json_data   JSONB;
    v_data_base64 TEXT;
BEGIN
    IF TG_OP = 'INSERT' THEN
        v_action_type := 'INSERT';
        v_json_data := jsonb_build_object(
            'id', NEW.id,
            'customer_id', NEW.customer_id,
            'order_date', to_char(NEW.order_date, 'YYYY-MM-DD"T"HH24:MI:SS'),
            'status', NEW.status,
            'total_amount', NEW.total_amount,
            'currency', NEW.currency,
            'notes', NEW.notes,
            'created_at', to_char(NEW.created_at, 'YYYY-MM-DD"T"HH24:MI:SS')
        );

    ELSIF TG_OP = 'UPDATE' THEN
        v_action_type := 'UPDATE';
        v_json_data := jsonb_build_object(
            'id', NEW.id,
            'customer_id', NEW.customer_id,
            'order_date', to_char(NEW.order_date, 'YYYY-MM-DD"T"HH24:MI:SS'),
            'status', NEW.status,
            'total_amount', NEW.total_amount,
            'currency', NEW.currency,
            'notes', NEW.notes,
            'created_at', to_char(NEW.created_at, 'YYYY-MM-DD"T"HH24:MI:SS')
        );

    ELSIF TG_OP = 'DELETE' THEN
        v_action_type := 'DELETE';
        v_json_data := jsonb_build_object(
            'id', OLD.id,
            'customer_id', OLD.customer_id,
            'order_date', to_char(OLD.order_date, 'YYYY-MM-DD"T"HH24:MI:SS'),
            'status', OLD.status,
            'total_amount', OLD.total_amount,
            'currency', OLD.currency,
            'notes', OLD.notes,
            'created_at', to_char(OLD.created_at, 'YYYY-MM-DD"T"HH24:MI:SS')
        );
    END IF;

    -- Encode JSON as base64
    v_data_base64 := encode(convert_to(v_json_data::text, 'UTF8'), 'base64');

    -- Insert into change_tracking table
    INSERT INTO change_tracking (
        table_name,
        type,
        data_content_type,
        data,
        data_base64
    )
    VALUES (
        'ORDERS',
        v_action_type,
        'application/json',
        v_json_data,
        v_data_base64
    );

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- Create trigger
CREATE TRIGGER trg_orders_change_tracking
AFTER INSERT OR UPDATE OR DELETE ON orders
FOR EACH ROW
EXECUTE FUNCTION trg_orders_change_tracking_fn();
```

### Test Procedure

```sql
-- Insert test record
INSERT INTO ORDERS (CUSTOMER_ID, TOTAL_AMOUNT) VALUES (101, 150.00);

-- Check change tracking
SELECT * FROM CHANGE_TRACKING WHERE TABLE_NAME = 'ORDERS' ORDER BY CREATED_AT DESC;

-- Update record
UPDATE ORDERS SET STATUS = 'SHIPPED', TOTAL_AMOUNT = 175.00 WHERE CUSTOMER_ID = 101;

-- Check for update
SELECT * FROM CHANGE_TRACKING WHERE TYPE = 'UPDATE' AND TABLE_NAME = 'ORDERS' ORDER BY CREATED_AT DESC;

-- Delete record
DELETE FROM ORDERS WHERE CUSTOMER_ID = 101;

-- Check for delete
SELECT * FROM CHANGE_TRACKING WHERE TYPE = 'DELETE' AND TABLE_NAME = 'ORDERS' ORDER BY CREATED_AT DESC;
```

---

## Kafka Connect Configuration (JDBC Source)c

**see: [Configuration Reference for JDBC Source Connector](https://docs.confluent.io/kafka-connectors/jdbc/10.9/source-connector/source_config_options.html)**

### Set oracle-source-connector.json (Save it in ./provision/connectors/oracle-source-connector.json)

```json
{
   "name": "oracle-source-connector",
   "config": {
      "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
      "connection.url": "jdbc:oracle:thin:@oracledb:1521/XEPDB1",
      "connection.oracle.jdbc.ReadTimeout": "45000",
      "connection.user": "SYSTEM",
      "connection.password": "MySecurePassword123",
      "table.whitelist": "CHANGE_TRACKING",
      "table.blacklist": "",
      "schema.pattern": "SYSTEM",
      "mode": "timestamp+incrementing",
      "timestamp.column.name": "CREATED_AT",
      "incrementing.column.name": "ID",
      "topic.prefix": "oracle_events_",
      "poll.interval.ms": 5000,
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": false,
      "topic.creation.enable": true,
      "topic.creation.default.replication.factor": 3,
      "topic.creation.default.partitions": 5
   }
}
```

### Set postgres-source-connector.json (Save it in ./provision/connectors/postgres-source-connector.json)
```json
{
  "name": "postgres-source-connector",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url": "jdbc:postgresql://postgres:5432/postgres",
    "connection.user": "postgres",
    "connection.password": "postgres",

    "table.whitelist": "change_tracking",
    "table.blacklist": "",
    "schema.pattern": "public",

    "mode": "timestamp+incrementing",
    "timestamp.column.name": "created_at",
    "incrementing.column.name": "id",

    "topic.prefix": "postgres_events_",
    "poll.interval.ms": 5000,

    "key.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false,

    "topic.creation.enable": true,
    "topic.creation.default.replication.factor": 1,
    "topic.creation.default.partitions": 1
  }
}
```

### Deploy connector
```bash
   curl -X POST -H "Content-Type: application/json" \
   --data @./provision/connectors/oracle-source-connector.json \
   http://localhost:8083/connectors || true && wait
```

### Check connector status
```bash
  curl -s http://localhost:8083/connectors/oracle-source-connector/status | jq
```

### Check connector config
```bash
   curl -s http://localhost:8083/connectors/oracle-source-connector/config | jq
```

### Check connector offsets
```bash
  curl -s http://localhost:8083/connectors/oracle-source-connector/offsets | jq .
```

### Restart the connector
```bash
  curl -X POST http://localhost:8083/connectors/oracle-source-connector/restart
```

### Pause the connector
```bash
   curl -X PUT -H "Content-Type: application/json" \
   --data '{"paused":true}' \
   http://localhost:8083/connectors/oracle-source-connector/pause
```

### Stop the connector
```bash
   curl -X PUT -H "Content-Type: application/json" \
   --data '{"paused":true}' \
   http://localhost:8083/connectors/oracle-source-connector/stop
```

### Resume the connector
```bash
   curl -X PUT -H "Content-Type: application/json" \
     --data '{"paused":false}' \
     http://localhost:8083/connectors/oracle-source-connector/resume
```

### Delete connector
```bash
  curl -X DELETE http://localhost:8083/connectors/oracle-source-connector
```

### Check kafka-connect logs
```batch
   docker logs -f kafka-connect
```

### Check kafka topics
```bash
  docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list | grep oracle
```

### Delete connector offset topic (this forces the connector to start from scratch):
```bash
  docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic docker-connect-offsets
```


